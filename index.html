<!doctype html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

        <title>Question Answering with Knowledge Graph</title>

        <link rel="stylesheet" href="css/reveal.css">
        <link rel="stylesheet" href="css/theme/black.css">

        <!-- Theme used for syntax highlighting of code -->
        <link rel="stylesheet" href="lib/css/zenburn.css">

        <!-- Printing and PDF exports -->
        <script>
            var link = document.createElement( 'link' );
            link.rel = 'stylesheet';
            link.type = 'text/css';
            link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
            document.getElementsByTagName( 'head' )[0].appendChild( link );
        </script>
    </head>
    <body>
        <div class="reveal">
            <div class="slides">
                <section>
                    <h4>Natural Language Supported Relation Matching for Question Answering with Knowledge Graphs</h4>

                    <br><br><br>

                    <p style="font-size:50%;">
                        Hongyu Li, Chenyan Xiong, Jamie Callan
                    </p>

                    <p style="font-size:50%;">
                        Carnegie Mellon University
                    </p>
                </section>

                <section>
                    <h3>Roadmap</h3>
                    <ul style="font-size:70%;">
                        <li>What task?</li> 
                            <ul>
                                <li>Question Answering with Knowledge Graph</li>
                            </ul>
                        <li>System Architecture</li>
                        <li>Relation Matching</li>
                            <ul>
                                <li>Semantic Parsing with LSTM</li>
                                <li>Wikipedia Support Sentences</li>
                            </ul>
                        <li>Experiment Results & Analysis</li>
                    </ul>
                </section>

                <section id="fragments">
                    <p class="fragment">Where is Carnegie Mellon University?</p>
                    <p class="fragment">Who founded Google?</p>
                    <p class="fragment">Who inspired Obama?</p>
                    <p class="fragment">Where did the latin language originate from?</p>
                    <p class="fragment">...</p>
                </section>

                <section>
                    <section id="fragments">
                        <img data-src="media/Freebase_Logo_optimised.png">
                        <aside class="notes">
                            Where does the answer come from? In this research, we built our QA
                            system based on knowledge bases. More specifically, we are using
                            Freebase as our major data source.
                            Freebase is a large collaborative knowledge base currently maintained by Google.
                            Essentially, Freebase is just a list of triples in the format of
                        </aside>
                    </section>
                </section>

                <section data-background-iframe="http://xiaozhuyfk.github.io/AMA_Network" data-background-interactive>

                </section>

                <section data-background-color="#ffffff">
                    <h4>System Architecture</h4>
                    <img data-src="media/system.png">
                    <aside class="notes">

                    </aside>
                </section>

                <section>
                    <h3>Relation Matching</h3>
                    <ul style="font-size:80%;">
                        <li>Semantic Parsing with LSTM</li>
                        <li>Wikipedia Support Sentences</li>
                    </ul>
                    <aside class="notes">
                        From the demo, we can see that there are two major challeges. One is
                        the relation matching problem, which is how can find the relationship
                        that answers the question.
                    </aside>
                </section>

                <!-- <section>
                    <h4>Long Short Term Memory (LSTM)</h4>
                    <img data-src="media/LSTM3-chain.png">
                    <aside class="notes">
                        Long Short Term Memory networks – usually just called “LSTMs” –
                        are a special kind of RNN, capable of learning long-term dependencies.
                        The motivation for using LSTM is that LSTM has been proved to be quite
                        effective when solving machine translation problems, and matching relations
                        can be considered as a form of translation.
                    </aside>
                </section> -->

                <section>
                    <h4>Semantic Parsing with LSTM</h4>
                    <img data-src="media/lstm.png">
                    <aside class="notes">

                    </aside>
                </section>

                <section>
                    <h4>Training</h4>
                    <ul>
                        <li>Both models trained pairwisely</li>
                        <li>Each training instance is a pair of fact candidates</li>
                        <li>Use letter-trigrams for input word sequence</li>
                        <ul>
                            <li>"who" --- "#wh" + "who" + "ho#"</li>
                            <li>reduce vocabulary size</li>
                            <li>spelling errors</li>
                        </ul>
                    </ul>
                </section>

                <section>
                    <h4>Wikipedia Support Sentence Extraction</h4>
                    <ul>
                        <li>Data: enwiki data dump (.xml)</li>
                        <li>For candidate triple (s, r, o), extract sentences containing both s, o</li>
                        <li>Choose the best support sentence based on similarity</li>
                    </ul>
                </section>

                <section>
                    <h4>Feature Representation</h4>
                    <img data-src="media/features.png" width="800">
                    <aside class="notes">
                        Feature 1: Popularity score aims to measure the quality of idenAfied enAty
                        Feature 2: Number of support sentences reflects the popularity of the relation
                        edge
                        Feature 3: Term overlap between quesAon and top support sentence
                        Feature 4: Term overlap between fact candidate and top support sentence
                        Feature 5-8: QuesAon-RelaAon similarity scores computed by LSTM Ranking,
                        LSTM Joint, LSTM Joint Pre-train and CDSSM models
                        Feature 9-12: QuesAon-Support Sentence similarity scores computed by the
                        deep learning models
                    </aside>
                </section>

                <section>
                    <h4>Evaluation</h4>
                    <ul>
                        <li>Dataset: WebQuestions</li>
                        <li>3778 training questions, 2032 testing questions</li>
                        <li>Performance evaluated by average recall, precision, F1 measure</li>
                    </ul>
                    <aside class="notes">
                        Reference answers of the questions are obtained by crowd sourcing
                    </aside>
                </section>

                <section>
                    <img data-src="media/result1.png">
                </section>

                <section>
                    <img data-src="media/result2.png">
                </section>

                <section>
                    <img data-src="media/error.png">
                </section>

                <section>
                    <h3>Questions?</h3>
                </section>

            </div>
        </div>

        <script src="lib/js/head.min.js"></script>
        <script src="js/reveal.js"></script>

        <script>
            // More info about config & dependencies:
            // - https://github.com/hakimel/reveal.js#configuration
            // - https://github.com/hakimel/reveal.js#dependencies
            Reveal.initialize({
                dependencies: [
                    { src: 'plugin/markdown/marked.js' },
                    { src: 'plugin/markdown/markdown.js' },
                    { src: 'plugin/notes/notes.js', async: true },
                    { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
                ]
            });

            // Shows the slide number using default formatting
            // Reveal.configure({ slideNumber: true });

            // Slide number formatting can be configured using these variables:
            //  "h.v":  horizontal . vertical slide number (default)
            //  "h/v":  horizontal / vertical slide number
            //    "c":  flattened slide number
            //  "c/t":  flattened slide number / total slides
            Reveal.configure({ slideNumber: 'c/t' });
        </script>
    </body>
</html>
